{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/25AlecZ/PredictingPlayerValue/blob/main/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries + packages"
      ],
      "metadata": {
        "id": "fQNefTLMhsSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "g8dYbjDy4gsU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53961fc5-7307-4b06-91c4-87a4be1762e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install packages\n",
        "!pip install --upgrade pip\n",
        "!pip install pandas --upgrade pip\n",
        "#!pip install scikit-learn --upgrade pip\n",
        "!pip install xgboost --upgrade pip\n",
        "!pip install sklearn --upgrade pip\n",
        "!pip install shap"
      ],
      "metadata": {
        "id": "BGGoSlzQ6RvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a366fd-f6d6-449d-8736-8757ce9885c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.2\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Downloading tzdata-2023.4-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading pandas-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tzdata, pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "bigframes 0.19.1 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.2.0 tzdata-2023.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting shap\n",
            "  Downloading shap-0.44.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.0)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n",
            "Collecting slicer==0.0.7 (from shap)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
            "Downloading shap-0.44.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (533 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m533.5/533.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: slicer, shap\n",
            "Successfully installed shap-0.44.0 slicer-0.0.7\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import modules\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import shap\n",
        "import gc"
      ],
      "metadata": {
        "id": "VNAdHaTOMNAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Cleaning"
      ],
      "metadata": {
        "id": "vDdQiyGQj7xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "playerdf2018 = pd.read_csv('/content/drive/MyDrive/PlayerValue/playerdf2018.csv')\n",
        "playerdf2018.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "playerdf2019 = pd.read_csv('/content/drive/MyDrive/PlayerValue/playerdf2019.csv')\n",
        "playerdf2019.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "playerdf2020 = pd.read_csv('/content/drive/MyDrive/PlayerValue/playerdf2020.csv')\n",
        "playerdf2020.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "playerdf2021 = pd.read_csv('/content/drive/MyDrive/PlayerValue/playerdf2021.csv')\n",
        "playerdf2021.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "playerdf2022 = pd.read_csv('/content/drive/MyDrive/PlayerValue/playerdf2022.csv')\n",
        "playerdf2022.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "playerdf2023 = pd.read_csv('/content/drive/MyDrive/PlayerValue/playerdf2023.csv')\n",
        "playerdf2023.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "InjuryYearDurationUpdatedYearsdf = pd.read_csv('/content/drive/MyDrive/PlayerValue/InjuryYearDurationUpdatedYearsdf.csv')\n",
        "InjuryYearDurationUpdatedYearsdf.drop('Unnamed: 0', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "zlo_UvST9rfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "playerFrebdf = pd.concat([playerdf2018,playerdf2019, playerdf2020, playerdf2021, playerdf2022, playerdf2023], ignore_index = True)"
      ],
      "metadata": {
        "id": "VkTFd0kEcuAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#concat all season dataframes from freb datasets\n",
        "playerFrebdf['Age'] = pd.to_numeric(playerFrebdf['Age'])\n",
        "playerFrebdf.rename(columns = {'player_url':'Player_url'}, inplace = True)\n",
        "playerFrebdf = playerFrebdf.merge(InjuryYearDurationUpdatedYearsdf, on = 'Player_url', how = 'left')\n",
        "playerFrebdf.count()\n",
        "#no blank spaces in column names\n",
        "#playerFrebdf.columns = playerFrebdf.columns.str.replace(' ','_')\n",
        "#playerFrebdf['player_height_mtrs'] = pd.to_numeric(playerFrebdf['player_height_mtrs'])\n",
        "#playerFrebdf.to_csv('/content/drive/MyDrive/PlayerValue/Frebdf.csv')"
      ],
      "metadata": {
        "id": "k-DZ9m9CY-_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#Injury with regular column names\n",
        "Injury2018df = pd.read_csv('/content/drive/MyDrive/PlayerValue/Injury2018df.csv')\n",
        "Injury2018df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "Injury2019df = pd.read_csv('/content/drive/MyDrive/PlayerValue/Injury2019df.csv')\n",
        "Injury2019df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "Injury2020df = pd.read_csv('/content/drive/MyDrive/PlayerValue/Injury2020df.csv')\n",
        "Injury2020df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "Injury2021df = pd.read_csv('/content/drive/MyDrive/PlayerValue/Injury2021df.csv')\n",
        "Injury2021df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "Injury2022df = pd.read_csv('/content/drive/MyDrive/PlayerValue/Injury2022df.csv')\n",
        "Injury2022df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "Injury2023df = pd.read_csv('/content/drive/MyDrive/PlayerValue/Injury2023df.csv')\n",
        "Injury2023df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "#Injury with columns names including year in duration and type of injury\n",
        "Injury2018YearDurationdf = pd.read_csv('/content/drive/MyDrive/PlayerValue/Injury2018YearDurationdf.csv')\n",
        "Injury2018YearDurationdf.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "Injury2019YearDurationdf = pd.read_csv('/content/drive/MyDrive/PlayerValue/Injury2019YearDurationdf.csv')\n",
        "Injury2019YearDurationdf.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "Injury2020YearDurationdf = pd.read_csv('/content/drive/MyDrive/PlayerValue/Injury2020YearDurationdf.csv')\n",
        "Injury2020YearDurationdf.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "Injury2021YearDurationdf = pd.read_csv('/content/drive/MyDrive/PlayerValue/Injury2021YearDurationdf.csv')\n",
        "Injury2021YearDurationdf.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "Injury2022YearDurationdf = pd.read_csv('/content/drive/MyDrive/PlayerValue/Injury2022YearDurationdf.csv')\n",
        "Injury2022YearDurationdf.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "Injury2023YearDurationdf = pd.read_csv('/content/drive/MyDrive/PlayerValue/Injury2023YearDurationdf.csv')\n",
        "Injury2023YearDurationdf.drop('Unnamed: 0', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "ffahE_GFQYa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "Injury2018df.rename(columns = {'Player_url':'player_url'}, inplace = True)\n",
        "Injury2019df.rename(columns = {'Player_url':'player_url'}, inplace = True)\n",
        "Injury2020df.rename(columns = {'Player_url':'player_url'}, inplace = True)\n",
        "Injury2021df.rename(columns = {'Player_url':'player_url'}, inplace = True)\n",
        "Injury2022df.rename(columns = {'Player_url':'player_url'}, inplace = True)\n",
        "Injury2023df.rename(columns = {'Player_url':'player_url'}, inplace = True)"
      ],
      "metadata": {
        "id": "mrhRfM3OBUHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#Injury Model\n",
        "#Concatenate all data into overall injury df, then for loop search for player name, check player year duration and type duration, then replace NaN values with 0\n",
        "InjuryYearDurationdf = pd.concat([Injury2018YearDurationdf, Injury2019YearDurationdf], ignore_index = True)\n",
        "InjuryYearDurationdf = pd.concat([InjuryYearDurationdf, Injury2020YearDurationdf], ignore_index = True)\n",
        "InjuryYearDurationdf = pd.concat([InjuryYearDurationdf, Injury2021YearDurationdf], ignore_index = True)\n",
        "InjuryYearDurationdf = pd.concat([InjuryYearDurationdf, Injury2022YearDurationdf], ignore_index = True)\n",
        "InjuryYearDurationdf = pd.concat([InjuryYearDurationdf, Injury2023YearDurationdf], ignore_index = True)"
      ],
      "metadata": {
        "id": "p9RVmvcYh53F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "for i in range(0, len(InjuryYearDurationdf)):\n",
        "  playerUrl = InjuryYearDurationdf.loc[i, \"Player_url\"]\n",
        "  for j in range(i, len(InjuryYearDurationdf)):\n",
        "    if (InjuryYearDurationdf.loc[j, \"Player_url\"] == playerUrl):\n",
        "        if (not InjuryYearDurationdf.isnull().loc[j, \"Duration_2019\"]):\n",
        "          InjuryYearDurationdf.loc[i, \"Duration_2019\"] = InjuryYearDurationdf.loc[j, \"Duration_2019\"]\n",
        "          InjuryYearDurationdf.loc[i, \"Type_2019\"] = InjuryYearDurationdf.loc[j, \"Type_2019\"]\n",
        "        elif (not InjuryYearDurationdf.isnull().loc[j, \"Duration_2020\"]):\n",
        "          InjuryYearDurationdf.loc[i, \"Duration_2020\"] = InjuryYearDurationdf.loc[j, \"Duration_2020\"]\n",
        "          InjuryYearDurationdf.loc[i, \"Type_2020\"] = InjuryYearDurationdf.loc[j, \"Type_2020\"]\n",
        "        elif (not InjuryYearDurationdf.isnull().loc[j, \"Duration_2021\"]):\n",
        "          InjuryYearDurationdf.loc[i, \"Duration_2021\"] = InjuryYearDurationdf.loc[j, \"Duration_2021\"]\n",
        "          InjuryYearDurationdf.loc[i, \"Type_2021\"] = InjuryYearDurationdf.loc[j, \"Type_2021\"]\n",
        "        elif (not InjuryYearDurationdf.isnull().loc[j, \"Duration_2022\"]):\n",
        "          InjuryYearDurationdf.loc[i, \"Duration_2022\"] = InjuryYearDurationdf.loc[j, \"Duration_2022\"]\n",
        "          InjuryYearDurationdf.loc[i, \"Type_2022\"] = InjuryYearDurationdf.loc[j, \"Type_2022\"]\n",
        "        elif (not InjuryYearDurationdf.isnull().loc[j, \"Duration_2023\"]):\n",
        "          InjuryYearDurationdf.loc[i, \"Duration_2023\"] = InjuryYearDurationdf.loc[j, \"Duration_2023\"]\n",
        "          InjuryYearDurationdf.loc[i, \"Type_2023\"] = InjuryYearDurationdf.loc[j, \"Type_2023\"]\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "B2rTIqDizIws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "playerdf2018 = playerdf2018.merge(Injury2018df, on = 'player_url', how = 'left')\n",
        "playerdf2019 = playerdf2019.merge(Injury2019df, on = 'player_url', how = 'left')\n",
        "playerdf2020 = playerdf2020.merge(Injury2020df, on = 'player_url', how = 'left')\n",
        "playerdf2021 = playerdf2021.merge(Injury2021df, on = 'player_url', how = 'left')\n",
        "playerdf2022 = playerdf2022.merge(Injury2022df, on = 'player_url', how = 'left')\n",
        "playerdf2023 = playerdf2023.merge(Injury2023df, on = 'player_url', how = 'left')"
      ],
      "metadata": {
        "id": "VrGa9tXG-t5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#concat all season dataframes from freb datasets\n",
        "playerFrebdf = pd.concat([playerdf2018,playerdf2019, playerdf2020, playerdf2021, playerdf2022, playerdf2023], ignore_index = True)\n",
        "playerFrebdf['Age'] = pd.to_numeric(playerFrebdf['Age'])\n",
        "playerFrebdf['player_height_mtrs'] = pd.to_numeric(playerFrebdf['player_height_mtrs'])\n",
        "playerFrebdf.sample(2)"
      ],
      "metadata": {
        "id": "Rrp_4dwe8-8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Original Dataset and sliding windows"
      ],
      "metadata": {
        "id": "MLqZrP1BiKHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "InjuryYearDurationUpdatedYearsdf = InjuryYearDurationUpdatedYearsdf.drop_duplicates(subset=['Player_url'], keep = 'first')\n",
        "InjuryYearDurationUpdatedYearsdf.count()\n",
        "InjuryYearDurationUpdatedYearsdf.to_csv('/content/drive/MyDrive/PlayerValue/InjuryYearDurationUpdatedYearsdf.csv')"
      ],
      "metadata": {
        "id": "k6OolJLogtct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "#Clean dataframe so that each row only has one injury from that season year\n",
        "for i in range (0, len(InjuryModeldf)):\n",
        "  Year = InjuryModeldf.loc[i, 'Season_End_Year']\n",
        "  if (Year == 2018):\n",
        "    InjuryModeldf.at[i, 'Duration_2019'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2019'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2020'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2020'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2021'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2021'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2022'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2022'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2023'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2023'] = np.nan\n",
        "  elif (Year == 2019):\n",
        "    InjuryModeldf.at[i, 'Duration_2018'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2018'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2020'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2020'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2021'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2021'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2022'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2022'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2023'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2023'] = np.nan\n",
        "  elif (Year == 2020):\n",
        "    InjuryModeldf.at[i, 'Duration_2018'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2018'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2019'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2019'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2021'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2021'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2022'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2022'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2023'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2023'] = np.nan\n",
        "  elif (Year == 2021):\n",
        "    InjuryModeldf.at[i, 'Duration_2018'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2018'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2019'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2019'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2020'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2020'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2022'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2022'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2023'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2023'] = np.nan\n",
        "  elif (Year == 2022):\n",
        "    InjuryModeldf.at[i, 'Duration_2018'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2018'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2019'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2019'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2020'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2020'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2021'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2021'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2023'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2023'] = np.nan\n",
        "  elif (Year == 2023):\n",
        "    InjuryModeldf.at[i, 'Duration_2018'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2018'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2019'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2019'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2020'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2020'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2021'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2021'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Duration_2022'] = np.nan\n",
        "    InjuryModeldf.at[i, 'Type_2022'] = np.nan\n",
        "\n",
        "#InjuryModeldf.to_csv('/content/drive/MyDrive/PlayerValue/FrebInjuryPerYear.csv')"
      ],
      "metadata": {
        "id": "t6EFJvcakvTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "InjuryModeldf = pd.read_csv('/content/drive/MyDrive/PlayerValue/FrebInjuryPerYear.csv')\n",
        "InjuryModeldf.drop('Unnamed: 0', axis=1, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLVjOkLscAXi",
        "outputId": "d50bfa4c-fdac-45c9-d2b8-6c8c65270243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Columns (233,242,245,247,249,251,253) have mixed types. Specify dtype option on import or set low_memory=False.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Testdf = pd.read_csv('/content/drive/MyDrive/PlayerValue/Testdf.csv')\n",
        "Testdf.drop('Unnamed: 0', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "AyFA1WlSEjcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Testdf.to_csv('/content/drive/MyDrive/PlayerValue/Testdfmodified.csv')"
      ],
      "metadata": {
        "id": "RMYBIuk5uKTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Testdf = pd.read_csv('/content/drive/MyDrive/PlayerValue/Testdfmodified.csv')\n",
        "Testdf.drop('Unnamed: 0', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "a4DqNbCDum_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "Testdf = InjuryModeldf.copy()\n",
        "for i in range (0, len(InjuryModeldf)):\n",
        "  print(i)\n",
        "  if (not (InjuryModeldf.loc[i, 'Player_x'] == 'John Stones' or InjuryModeldf.loc[i, 'Player_x'] == 'Danny Welbeck')):\n",
        "    Testdf.drop(i, inplace = True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4ehl3L9A_vC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make sure to include type\n",
        "#parameter years needed, concatenate dataframe and add injury duration + ground truth\n",
        "def slidingWindowstest(years):\n",
        "  InjuryDurationdf = pd.DataFrame()\n",
        "  #truth dataframe for only duration of injuries across years\n",
        "  InjuryDurationdf['duration_truth'] = np.nan\n",
        "  #dataframe for stats across all years\n",
        "  Statsdf = Testdf.copy()\n",
        "\n",
        "  for year in range(1, years):\n",
        "    for col in Testdf.columns:\n",
        "      #duplicates columns for years-1\n",
        "      Statsdf[str(col) + 'year' + str(year+1)] = np.nan\n",
        "\n",
        "  Statsdf['duration'] = 0\n",
        "  Statsdf['injuryType'] = ''\n",
        "\n",
        "\n",
        "\n",
        "#concatenating dataframe\n",
        "  for originalRow in range (0, len(Statsdf)):\n",
        "    print('OriginalRow: ' + str(originalRow))\n",
        "    url = Statsdf.loc[originalRow, 'Url']\n",
        "    originalSeason = Statsdf.loc[originalRow, 'Season_End_Year'] #2018\n",
        "    truthSeason = originalSeason + years #2019\n",
        "    foundtruth = False\n",
        "    #duration not working properly for year one, truth duration also doesn't work\n",
        "    if (not str(Statsdf.loc[originalRow, 'Type_' + str(originalSeason)]) == 'nan'):\n",
        "      Statsdf.loc[originalRow, 'injuryType'] += str(Statsdf.loc[originalRow, 'Type_' + str(originalSeason)])\n",
        "    if (not str(Statsdf.loc[originalRow, 'Duration_' + str(originalSeason)]) == 'nan'):\n",
        "      Statsdf.loc[originalRow, 'duration'] += Statsdf.loc[originalRow, 'Duration_' + str(originalSeason)]\n",
        "\n",
        "    if (truthSeason > 2023):\n",
        "      break\n",
        "    for changedRow in range (originalRow, len(Statsdf)):\n",
        "      currentSeason = Statsdf.loc[changedRow, 'Season_End_Year'] #2019\n",
        "      if (currentSeason > truthSeason):\n",
        "        break\n",
        "      #if url matches\n",
        "      if (Statsdf.loc[changedRow, 'Url'] == url and currentSeason > originalSeason):\n",
        "        #year is not truth\n",
        "        if (currentSeason < truthSeason):\n",
        "          #iterate through all columns to concatenate to original row\n",
        "          for col in range(0, len(Testdf.columns)):\n",
        "            Statsdf.iloc[originalRow, (col + (currentSeason - originalSeason) * len(Testdf.columns))] = Statsdf.iloc[changedRow, col]\n",
        "          if ((not str(Statsdf.loc[changedRow, 'Type_' + str(currentSeason)]) == 'nan') and years != 1):\n",
        "            Statsdf.loc[originalRow, 'injuryType'] += str(Statsdf.loc[changedRow, 'Type_' + str(currentSeason)]) #should it be currentSeason?\n",
        "          if ((not str(Statsdf.loc[changedRow, 'Duration_' + str(currentSeason)]) == 'nan') and years != 1):\n",
        "            Statsdf.loc[originalRow, 'duration'] += Statsdf.loc[changedRow, 'Duration_' + str(currentSeason)]\n",
        "\n",
        "        #if year is truth, add duration of injury\n",
        "        elif (currentSeason == truthSeason):\n",
        "          foundtruth = True\n",
        "          if (str(Statsdf.loc[changedRow, 'Duration_' + str(truthSeason)]) == 'nan'):\n",
        "            InjuryDurationdf.loc[len(InjuryDurationdf), 'duration_truth'] = 0\n",
        "          else:\n",
        "            InjuryDurationdf.loc[len(InjuryDurationdf), 'duration_truth'] = Statsdf.loc[changedRow, 'Duration_' + str(truthSeason)]\n",
        "          break;\n",
        "\n",
        "    if (foundtruth == False):\n",
        "      InjuryDurationdf.loc[len(InjuryDurationdf), 'duration_truth'] = np.nan\n",
        "\n",
        "#error may be how I am joining df\n",
        "\n",
        "  Statsdf = Statsdf.join(InjuryDurationdf)\n",
        "\n",
        "  #return modified df\n",
        "  return Statsdf"
      ],
      "metadata": {
        "id": "aLbGuIc7bpdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make sure to include type\n",
        "#parameter years needed, concatenate dataframe and add injury duration + ground truth\n",
        "def slidingWindows(years):\n",
        "  InjuryDurationdf = pd.DataFrame()\n",
        "  #truth dataframe for only duration of injuries across years\n",
        "  InjuryDurationdf['duration_truth'] = np.nan\n",
        "  #dataframe for stats across all years\n",
        "  Statsdf = InjuryModeldf.copy()\n",
        "\n",
        "  for year in range(1, years):\n",
        "    for col in InjuryModeldf.columns:\n",
        "      #duplicates columns for years-1\n",
        "      Statsdf[str(col) + 'year' + str(year+1)] = np.nan\n",
        "\n",
        "  Statsdf['duration'] = 0\n",
        "  Statsdf['injuryType'] = ''\n",
        "\n",
        "\n",
        "\n",
        "#concatenating dataframe\n",
        "  for originalRow in range (0, len(Statsdf)):\n",
        "    print('OriginalRow: ' + str(originalRow))\n",
        "    url = Statsdf.loc[originalRow, 'Url']\n",
        "    originalSeason = Statsdf.loc[originalRow, 'Season_End_Year'] #2018\n",
        "    truthSeason = originalSeason + years #2019\n",
        "    foundtruth = False\n",
        "    #duration not working properly for year one, truth duration also doesn't work\n",
        "    if (not str(Statsdf.loc[originalRow, 'Type_' + str(originalSeason)]) == 'nan'):\n",
        "      Statsdf.loc[originalRow, 'injuryType'] += str(Statsdf.loc[originalRow, 'Type_' + str(originalSeason)])\n",
        "    if (not str(Statsdf.loc[originalRow, 'Duration_' + str(originalSeason)]) == 'nan'):\n",
        "      Statsdf.loc[originalRow, 'duration'] += Statsdf.loc[originalRow, 'Duration_' + str(originalSeason)]\n",
        "\n",
        "    if (truthSeason > 2023):\n",
        "      break\n",
        "    for changedRow in range (originalRow + 2800, len(Statsdf)):\n",
        "      currentSeason = Statsdf.loc[changedRow, 'Season_End_Year'] #2019\n",
        "      if (currentSeason > truthSeason):\n",
        "        break\n",
        "      #if url matches\n",
        "      if (Statsdf.loc[changedRow, 'Url'] == url and currentSeason > originalSeason):\n",
        "        #year is not truth\n",
        "        if (currentSeason < truthSeason):\n",
        "          #iterate through all columns to concatenate to original row\n",
        "          for col in range(0, len(Testdf.columns)):\n",
        "            Statsdf.iloc[originalRow, (col + (currentSeason - originalSeason) * len(Testdf.columns))] = Statsdf.iloc[changedRow, col]\n",
        "          if ((not str(Statsdf.loc[changedRow, 'Type_' + str(currentSeason)]) == 'nan') and years != 1):\n",
        "            Statsdf.loc[originalRow, 'injuryType'] += str(Statsdf.loc[changedRow, 'Type_' + str(currentSeason)]) #should it be currentSeason?\n",
        "          if ((not str(Statsdf.loc[changedRow, 'Duration_' + str(currentSeason)]) == 'nan') and years != 1):\n",
        "            Statsdf.loc[originalRow, 'duration'] += Statsdf.loc[changedRow, 'Duration_' + str(currentSeason)]\n",
        "\n",
        "        #if year is truth, add duration of injury\n",
        "        elif (currentSeason == truthSeason):\n",
        "          foundtruth = True\n",
        "          if (str(Statsdf.loc[changedRow, 'Duration_' + str(truthSeason)]) == 'nan'):\n",
        "            InjuryDurationdf.loc[len(InjuryDurationdf), 'duration_truth'] = 0\n",
        "          else:\n",
        "            InjuryDurationdf.loc[len(InjuryDurationdf), 'duration_truth'] = Statsdf.loc[changedRow, 'Duration_' + str(truthSeason)]\n",
        "          break;\n",
        "\n",
        "    if (foundtruth == False):\n",
        "      InjuryDurationdf.loc[len(InjuryDurationdf), 'duration_truth'] = np.nan\n",
        "\n",
        "#error may be how I am joining df\n",
        "\n",
        "  Statsdf = Statsdf.join(InjuryDurationdf)\n",
        "\n",
        "  #return modified df\n",
        "  return Statsdf"
      ],
      "metadata": {
        "id": "TIJzRZp1SRW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "InjuryModel5year = slidingWindows(5)"
      ],
      "metadata": {
        "id": "VVLUhWiPlZx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "InjuryModel5year.to_csv('/content/drive/MyDrive/PlayerValue/InjuryModel5year.csv')"
      ],
      "metadata": {
        "id": "2i39V6aGx8nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read concatenated csv\n"
      ],
      "metadata": {
        "id": "-_QGpx5eiSep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#read df for each year model\n",
        "InjuryModelOneYeardf = pd.read_csv('/content/drive/MyDrive/PlayerValue/InjuryModel1year.csv')\n",
        "InjuryModelOneYeardf.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "InjuryModelOneYeardf.drop(columns = ['Season_End_Year', 'season_start_year', 'Season', 'contract_expiry', 'player_num', 'player_name', 'Player_y', 'Player_x', 'comp_name', 'Url', 'Player_url', 'player_dob', 'player_nationality', 'current_club', 'squad','player_position', 'contract_expiry', 'date_joined', 'joined_from', 'player_market_value_euro', 'region','Duration_2018', 'Duration_2019', 'Duration_2020', 'Duration_2021', 'Duration_2022', 'Duration_2023', 'Type_2018', 'Type_2019','Type_2020', 'Type_2021', 'Type_2022', 'Type_2023'], inplace = True)\n",
        "x1year = InjuryModelOneYeardf.dropna(subset=['duration_truth'])\n",
        "y1year = x1year['duration_truth'].copy()"
      ],
      "metadata": {
        "id": "s70a2K-sGQdB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f2c8d27-b91c-4e46-c811-693c9042e1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Columns (233,242,245,247,249,251,253,255) have mixed types. Specify dtype option on import or set low_memory=False.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "InjuryModelTwoYeardf = pd.read_csv('/content/drive/MyDrive/PlayerValue/InjuryModel2year.csv')\n",
        "InjuryModelTwoYeardf.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "InjuryModelTwoYeardf.drop(columns = ['Season_End_Year', 'season_start_year', 'Season', 'contract_expiry', 'player_num', 'player_name', 'Player_y', 'Player_x', 'comp_name', 'Url', 'Player_url', 'player_dob', 'player_nationality', 'current_club', 'squad','player_position', 'contract_expiry', 'date_joined', 'joined_from', 'player_market_value_euro', 'region','Duration_2018', 'Duration_2019', 'Duration_2020', 'Duration_2021', 'Duration_2022', 'Duration_2023', 'Type_2018', 'Type_2019','Type_2020', 'Type_2021', 'Type_2022', 'Type_2023',\n",
        "                                     'Season_End_Yearyear2', 'season_start_yearyear2', 'Seasonyear2', 'contract_expiryyear2', 'player_numyear2', 'player_nameyear2', 'Player_yyear2', 'Player_xyear2', 'comp_nameyear2', 'Urlyear2', 'Player_urlyear2', 'player_dobyear2', 'player_nationalityyear2', 'current_clubyear2', 'squadyear2','player_positionyear2', 'contract_expiryyear2', 'date_joinedyear2', 'joined_fromyear2', 'player_market_value_euroyear2', 'regionyear2','Duration_2018year2', 'Duration_2019year2', 'Duration_2020year2', 'Duration_2021year2', 'Duration_2022year2', 'Duration_2023year2', 'Type_2018year2', 'Type_2019year2','Type_2020year2', 'Type_2021year2', 'Type_2022year2', 'Type_2023year2'], inplace = True)\n",
        "x2year = InjuryModelTwoYeardf.dropna(subset=['duration_truth'])\n",
        "y2year = x2year['duration_truth'].copy()"
      ],
      "metadata": {
        "id": "9yiKgvCpcuzm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f45b6808-f525-40e1-b798-b9e75ae75226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Columns (233,242,245,247,249,251,253,255,256,257,258,259,279,474,475,476,477,479,480,481,482,483,485,486,488,489,490,491,493,498,500,502,504,508) have mixed types. Specify dtype option on import or set low_memory=False.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "InjuryModelThreeYeardf = pd.read_csv('/content/drive/MyDrive/PlayerValue/InjuryModel3year.csv')\n",
        "InjuryModelThreeYeardf.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "InjuryModelThreeYeardf.drop(columns = ['Season_End_Year', 'season_start_year', 'Season', 'contract_expiry', 'player_num', 'player_name', 'Player_y', 'Player_x', 'comp_name', 'Url', 'Player_url', 'player_dob', 'player_nationality', 'current_club', 'squad','player_position', 'contract_expiry', 'date_joined', 'joined_from', 'player_market_value_euro', 'region','Duration_2018', 'Duration_2019', 'Duration_2020', 'Duration_2021', 'Duration_2022', 'Duration_2023', 'Type_2018', 'Type_2019','Type_2020', 'Type_2021', 'Type_2022', 'Type_2023',\n",
        "                                       'Season_End_Yearyear2', 'season_start_yearyear2', 'Seasonyear2', 'contract_expiryyear2', 'player_numyear2', 'player_nameyear2', 'Player_yyear2', 'Player_xyear2', 'comp_nameyear2', 'Urlyear2', 'Player_urlyear2', 'player_dobyear2', 'player_nationalityyear2', 'current_clubyear2', 'squadyear2','player_positionyear2', 'contract_expiryyear2', 'date_joinedyear2', 'joined_fromyear2', 'player_market_value_euroyear2', 'regionyear2','Duration_2018year2', 'Duration_2019year2', 'Duration_2020year2', 'Duration_2021year2', 'Duration_2022year2', 'Duration_2023year2', 'Type_2018year2', 'Type_2019year2','Type_2020year2', 'Type_2021year2', 'Type_2022year2', 'Type_2023year2',\n",
        "                                       'Season_End_Yearyear3', 'season_start_yearyear3', 'Seasonyear3', 'contract_expiryyear3', 'player_numyear3', 'player_nameyear3', 'Player_yyear3', 'Player_xyear3', 'comp_nameyear3', 'Urlyear3', 'Player_urlyear3', 'player_dobyear3', 'player_nationalityyear3', 'current_clubyear3', 'squadyear3','player_positionyear3', 'contract_expiryyear3', 'date_joinedyear3', 'joined_fromyear3', 'player_market_value_euroyear3', 'regionyear3','Duration_2018year3', 'Duration_2019year3', 'Duration_2020year3', 'Duration_2021year3', 'Duration_2022year3', 'Duration_2023year3', 'Type_2018year3', 'Type_2019year3','Type_2020year3', 'Type_2021year3', 'Type_2022year3', 'Type_2023year3'], inplace = True)\n",
        "x3year = InjuryModelThreeYeardf.dropna(subset=['duration_truth'])\n",
        "y3year = x3year['duration_truth'].copy()"
      ],
      "metadata": {
        "id": "0WkHYU8xeLZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39188081-75a5-45e4-b058-db063364f4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Columns (233,242,245,247,249,251,253,255,256,257,258,259,279,474,475,476,477,479,480,481,482,483,485,486,488,489,490,491,493,498,500,502,508,509,510,511,512,532,727,728,729,730,732,733,734,735,736,738,739,741,742,743,744,746,753,755,757,761) have mixed types. Specify dtype option on import or set low_memory=False.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "InjuryModelFourYeardf = pd.read_csv('/content/drive/MyDrive/PlayerValue/InjuryModel4year.csv')\n",
        "InjuryModelFourYeardf.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "InjuryModelFourYeardf.drop(columns = ['Season_End_Year', 'season_start_year', 'Season', 'contract_expiry', 'player_num', 'player_name', 'Player_y', 'Player_x', 'comp_name', 'Url', 'Player_url', 'player_dob', 'player_nationality', 'current_club', 'squad','player_position', 'contract_expiry', 'date_joined', 'joined_from', 'player_market_value_euro', 'region','Duration_2018', 'Duration_2019', 'Duration_2020', 'Duration_2021', 'Duration_2022', 'Duration_2023', 'Type_2018', 'Type_2019','Type_2020', 'Type_2021', 'Type_2022', 'Type_2023',\n",
        "                                     'Season_End_Yearyear2', 'season_start_yearyear2', 'Seasonyear2', 'contract_expiryyear2', 'player_numyear2', 'player_nameyear2', 'Player_yyear2', 'Player_xyear2', 'comp_nameyear2', 'Urlyear2', 'Player_urlyear2', 'player_dobyear2', 'player_nationalityyear2', 'current_clubyear2', 'squadyear2','player_positionyear2', 'contract_expiryyear2', 'date_joinedyear2', 'joined_fromyear2', 'player_market_value_euroyear2', 'regionyear2','Duration_2018year2', 'Duration_2019year2', 'Duration_2020year2', 'Duration_2021year2', 'Duration_2022year2', 'Duration_2023year2', 'Type_2018year2', 'Type_2019year2','Type_2020year2', 'Type_2021year2', 'Type_2022year2', 'Type_2023year2',\n",
        "                                     'Season_End_Yearyear3', 'season_start_yearyear3', 'Seasonyear3', 'contract_expiryyear3', 'player_numyear3', 'player_nameyear3', 'Player_yyear3', 'Player_xyear3', 'comp_nameyear3', 'Urlyear3', 'Player_urlyear3', 'player_dobyear3', 'player_nationalityyear3', 'current_clubyear3', 'squadyear3','player_positionyear3', 'contract_expiryyear3', 'date_joinedyear3', 'joined_fromyear3', 'player_market_value_euroyear3', 'regionyear3','Duration_2018year3', 'Duration_2019year3', 'Duration_2020year3', 'Duration_2021year3', 'Duration_2022year3', 'Duration_2023year3', 'Type_2018year3', 'Type_2019year3','Type_2020year3', 'Type_2021year3', 'Type_2022year3', 'Type_2023year3',\n",
        "                                     'Season_End_Yearyear4', 'season_start_yearyear4', 'Seasonyear4', 'contract_expiryyear4', 'player_numyear4', 'player_nameyear4', 'Player_yyear4', 'Player_xyear4', 'comp_nameyear4', 'Urlyear4', 'Player_urlyear4', 'player_dobyear4', 'player_nationalityyear4', 'current_clubyear4', 'squadyear4','player_positionyear4', 'contract_expiryyear4', 'date_joinedyear4', 'joined_fromyear4', 'player_market_value_euroyear4', 'regionyear4','Duration_2018year4', 'Duration_2019year4', 'Duration_2020year4', 'Duration_2021year4', 'Duration_2022year4', 'Duration_2023year4', 'Type_2018year4', 'Type_2019year4','Type_2020year4', 'Type_2021year4', 'Type_2022year4', 'Type_2023year4'], inplace = True)\n",
        "x4year = InjuryModelFourYeardf.dropna(subset=['duration_truth'])\n",
        "y4year = x4year['duration_truth'].copy()"
      ],
      "metadata": {
        "id": "-0wtJ5SwdUQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb38583-995d-4dfd-9f7d-ad9a88790c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Columns (233,242,245,247,249,251,253,255,256,257,258,259,279,474,475,476,477,479,480,481,482,483,485,486,488,489,490,491,493,498,500,508,509,510,511,512,532,727,728,729,730,732,733,734,735,736,738,739,741,742,743,744,746,753,755,761,762,763,764,765,785,980,981,982,983,985,986,987,988,989,991,992,994,995,996,997,999,1008,1010,1014) have mixed types. Specify dtype option on import or set low_memory=False.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "InjuryModelFiveYeardf = pd.read_csv('/content/drive/MyDrive/PlayerValue/InjuryModel5year.csv')\n",
        "InjuryModelFiveYeardf.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "InjuryModelFiveYeardf.drop(columns = ['Season_End_Year', 'season_start_year', 'Season', 'contract_expiry', 'player_num', 'player_name', 'Player_y', 'Player_x', 'comp_name', 'Url', 'Player_url', 'player_dob', 'player_nationality', 'current_club', 'squad','player_position', 'contract_expiry', 'date_joined', 'joined_from', 'player_market_value_euro', 'region','Duration_2018', 'Duration_2019', 'Duration_2020', 'Duration_2021', 'Duration_2022', 'Duration_2023', 'Type_2018', 'Type_2019','Type_2020', 'Type_2021', 'Type_2022', 'Type_2023',\n",
        "                                     'Season_End_Yearyear2', 'season_start_yearyear2', 'Seasonyear2', 'contract_expiryyear2', 'player_numyear2', 'player_nameyear2', 'Player_yyear2', 'Player_xyear2', 'comp_nameyear2', 'Urlyear2', 'Player_urlyear2', 'player_dobyear2', 'player_nationalityyear2', 'current_clubyear2', 'squadyear2','player_positionyear2', 'contract_expiryyear2', 'date_joinedyear2', 'joined_fromyear2', 'player_market_value_euroyear2', 'regionyear2','Duration_2018year2', 'Duration_2019year2', 'Duration_2020year2', 'Duration_2021year2', 'Duration_2022year2', 'Duration_2023year2', 'Type_2018year2', 'Type_2019year2','Type_2020year2', 'Type_2021year2', 'Type_2022year2', 'Type_2023year2',\n",
        "                                     'Season_End_Yearyear3', 'season_start_yearyear3', 'Seasonyear3', 'contract_expiryyear3', 'player_numyear3', 'player_nameyear3', 'Player_yyear3', 'Player_xyear3', 'comp_nameyear3', 'Urlyear3', 'Player_urlyear3', 'player_dobyear3', 'player_nationalityyear3', 'current_clubyear3', 'squadyear3','player_positionyear3', 'contract_expiryyear3', 'date_joinedyear3', 'joined_fromyear3', 'player_market_value_euroyear3', 'regionyear3','Duration_2018year3', 'Duration_2019year3', 'Duration_2020year3', 'Duration_2021year3', 'Duration_2022year3', 'Duration_2023year3', 'Type_2018year3', 'Type_2019year3','Type_2020year3', 'Type_2021year3', 'Type_2022year3', 'Type_2023year3',\n",
        "                                     'Season_End_Yearyear4', 'season_start_yearyear4', 'Seasonyear4', 'contract_expiryyear4', 'player_numyear4', 'player_nameyear4', 'Player_yyear4', 'Player_xyear4', 'comp_nameyear4', 'Urlyear4', 'Player_urlyear4', 'player_dobyear4', 'player_nationalityyear4', 'current_clubyear4', 'squadyear4','player_positionyear4', 'contract_expiryyear4', 'date_joinedyear4', 'joined_fromyear4', 'player_market_value_euroyear4', 'regionyear4','Duration_2018year4', 'Duration_2019year4', 'Duration_2020year4', 'Duration_2021year4', 'Duration_2022year4', 'Duration_2023year4', 'Type_2018year4', 'Type_2019year4','Type_2020year4', 'Type_2021year4', 'Type_2022year4', 'Type_2023year4',\n",
        "                                     'Season_End_Yearyear5', 'season_start_yearyear5', 'Seasonyear5', 'contract_expiryyear5', 'player_numyear5', 'player_nameyear5', 'Player_yyear5', 'Player_xyear5', 'comp_nameyear5', 'Urlyear5', 'Player_urlyear5', 'player_dobyear5', 'player_nationalityyear5', 'current_clubyear5', 'squadyear5','player_positionyear5', 'contract_expiryyear5', 'date_joinedyear5', 'joined_fromyear5', 'player_market_value_euroyear5', 'regionyear5','Duration_2018year5', 'Duration_2019year5', 'Duration_2020year5', 'Duration_2021year5', 'Duration_2022year5', 'Duration_2023year5', 'Type_2018year5', 'Type_2019year5','Type_2020year5', 'Type_2021year5', 'Type_2022year5', 'Type_2023year5',], inplace = True)\n",
        "x5year = InjuryModelFiveYeardf.dropna(subset=['duration_truth'])\n",
        "y5year = x5year['duration_truth'].copy()"
      ],
      "metadata": {
        "id": "Ev1rmHfqfaFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e647a75c-4e21-4add-8370-156aabfe163f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Columns (233,242,245,247,249,251,253,255,256,257,258,259,279,474,475,476,477,479,480,481,482,483,485,486,488,489,490,491,493,498,508,509,510,511,512,532,727,728,729,730,732,733,734,735,736,738,739,741,742,743,744,746,753,761,762,763,764,765,785,980,981,982,983,985,986,987,988,989,991,992,994,995,996,997,999,1008,1014,1015,1016,1017,1018,1038,1233,1234,1235,1236,1238,1239,1240,1241,1242,1244,1245,1247,1248,1249,1250,1252,1263,1267) have mixed types. Specify dtype option on import or set low_memory=False.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OneHotEncoding + SHAP for Injuries"
      ],
      "metadata": {
        "id": "_dOEf3IPikoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "types = x1year.dtypes"
      ],
      "metadata": {
        "id": "8b3stfYzmU7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(types)):\n",
        "  print(types[i])"
      ],
      "metadata": {
        "id": "tPdLr2s_mYd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "counter = 0\n",
        "for col in x1year.columns:\n",
        "  column_name = str(col)\n",
        "  if (x1year.column_name.dtype != \"object\"):\n",
        "    x1year.drop(counter, axis = 1)\n",
        "    counter = counter + 1"
      ],
      "metadata": {
        "id": "jY1AMqDVeRCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Year"
      ],
      "metadata": {
        "id": "7VtkaMRQl8Zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#One year model\n",
        "x1yearEncoding = pd.DataFrame()\n",
        "x1year[\"Squad\"] = x1year[\"Squad\"].astype(\"category\")\n",
        "extracted = x1year[\"Squad\"]\n",
        "x1year.drop(\"Squad\", axis = 1)\n",
        "x1yearEncoding = pd.concat([x1yearEncoding, extracted], axis=1)\n",
        "x1year[\"Comp\"] = x1year[\"Comp\"].astype(\"category\")\n",
        "extracted = x1year[\"Comp\"]\n",
        "x1year.drop(\"Comp\", axis = 1)\n",
        "x1yearEncoding = pd.concat([x1yearEncoding, extracted], axis=1)\n",
        "x1year[\"Pos\"] = x1year[\"Pos\"].astype(\"category\")\n",
        "extracted = x1year[\"Pos\"]\n",
        "x1year.drop(\"Pos\", axis = 1)\n",
        "x1yearEncoding = pd.concat([x1yearEncoding, extracted], axis=1)\n",
        "x1year[\"Nation\"] = x1year[\"Nation\"].astype(\"category\")\n",
        "extracted = x1year[\"Nation\"]\n",
        "x1year.drop(\"Nation\", axis = 1)\n",
        "x1yearEncoding = pd.concat([x1yearEncoding, extracted], axis=1)\n",
        "x1year[\"player_foot\"] = x1year[\"player_foot\"].astype(\"category\")\n",
        "extracted = x1year[\"player_foot\"]\n",
        "x1year.drop(\"player_foot\", axis = 1)\n",
        "x1yearEncoding = pd.concat([x1yearEncoding, extracted], axis=1)\n",
        "x1year[\"country\"] = x1year[\"country\"].astype(\"category\")\n",
        "extracted = x1year[\"country\"]\n",
        "x1year.drop(\"country\", axis = 1)\n",
        "x1yearEncoding = pd.concat([x1yearEncoding, extracted], axis=1)\n",
        "x1year[\"injuryType\"] = x1year[\"injuryType\"].astype(\"category\")\n",
        "extracted = x1year[\"injuryType\"]\n",
        "x1year.drop(\"injuryType\", axis = 1)\n",
        "x1yearEncoding = pd.concat([x1yearEncoding, extracted], axis=1)\n",
        "x1year.drop(['duration_truth'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "_CILygznGqPw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de7665aa-87c0-4cea-b574-ee8068965c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#One hot encoder also converting floats+duration to booleans\n",
        "\n",
        "enc = OneHotEncoder()\n",
        "enc.fit(x1yearEncoding)\n",
        "\n",
        "#transform categorical features\n",
        "X1year_encoded = enc.transform(x1yearEncoding).toarray()\n",
        "feature_names = x1yearEncoding.columns\n",
        "new_feature_names = enc.get_feature_names_out(feature_names)\n",
        "Xencoded = pd.DataFrame(X1year_encoded, columns= new_feature_names)"
      ],
      "metadata": {
        "id": "CVGoxTHEVC95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = x1year.join(Xencoded)"
      ],
      "metadata": {
        "id": "BwY7UadQklad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6tR1xDMlblw",
        "outputId": "b7c12c0a-b950-4849-9d52-8845a3ccd505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8987, 3144)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = x1year"
      ],
      "metadata": {
        "id": "OBzBxrLkn_FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1year_train, x1year_test, y1year_train, y1year_test = train_test_split(X, y1year, random_state=1, train_size = 0.8)\n",
        "InjuryModelXGB1year = XGBRegressor(tree_method=\"approx\", seed=1, enable_categorical = True)\n",
        "InjuryModelXGB1year.fit(x1year_train, y1year_train, verbose = True, early_stopping_rounds = 10, eval_set = [(x1year_test, y1year_test)])"
      ],
      "metadata": {
        "id": "z_xBciSWHLf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "cf1c4248-1e64-4c2c-fb9d-0fac238381c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-rmse:87.10556\n",
            "[1]\tvalidation_0-rmse:87.28685\n",
            "[2]\tvalidation_0-rmse:87.63194\n",
            "[3]\tvalidation_0-rmse:87.98877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4]\tvalidation_0-rmse:88.20354\n",
            "[5]\tvalidation_0-rmse:88.66903\n",
            "[6]\tvalidation_0-rmse:88.85886\n",
            "[7]\tvalidation_0-rmse:89.26891\n",
            "[8]\tvalidation_0-rmse:89.28460\n",
            "[9]\tvalidation_0-rmse:89.33695\n",
            "[10]\tvalidation_0-rmse:89.29079\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=True, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=True, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=True, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "InjuryModelXGB1year.save_model('InjuryModelXGB1year.json')\n",
        "#files.download('InjuryModelXGB1year.json')"
      ],
      "metadata": {
        "id": "MwPc0x3diUnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "InjuryModelXGB1year.load_model('InjuryModelXGB1year.json')"
      ],
      "metadata": {
        "id": "pylEQPtdiqG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y1year_pred = InjuryModelXGB1year.predict(x1year_test)\n",
        "shap_values = InjuryModelXGB1year.predict(XGBRegressor(x1year_test, enable_categorical=True), pred_contribs=True)\n",
        "#print(r2_score(y1year_test, y1year_pred))\n",
        "#print(mean_absolute_error(y1year_test, y1year_pred))\n",
        "#print(mean_squared_error(y1year_test, y1year_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "D7zgKQt3z314",
        "outputId": "c8e9c23d-5b68-408f-9998-06753dfccb81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Pass `objective` as keyword args.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "XGBModel.predict() got an unexpected keyword argument 'pred_contribs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-4e2369b64702>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#y1year_pred = InjuryModelXGB1year.predict(x1year_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInjuryModelXGB1year\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1year_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_categorical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contribs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(r2_score(y1year_test, y1year_pred))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(mean_absolute_error(y1year_test, y1year_pred))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(mean_squared_error(y1year_test, y1year_pred))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: XGBModel.predict() got an unexpected keyword argument 'pred_contribs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.TreeExplainer(InjuryModelXGB1year)\n",
        "shap_values = explainer(X)"
      ],
      "metadata": {
        "id": "GB7IC7NpWVuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values, X, plot_type='bar')"
      ],
      "metadata": {
        "id": "qzoUqup-ag-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# waterfall plot for first observation\n",
        "shap.plots.beeswarm(shap_values, max_display = 20)"
      ],
      "metadata": {
        "id": "UCbt_IhqX_y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(shap_values[0])"
      ],
      "metadata": {
        "id": "RxxuONAdXgqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(shap_values.base_values.shape)"
      ],
      "metadata": {
        "id": "jkVGIU61YL4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGB Injuries model"
      ],
      "metadata": {
        "id": "wSy-dKQ5jJ_o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Year"
      ],
      "metadata": {
        "id": "8RfqyfcsmIA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Iterating thorugh hyperparameters of model\n",
        "x1year_train, x1year_test, y1year_train, y1year_test = train_test_split(x1year, y1year, random_state=1, train_size = 0.8)\n",
        "for depth in [None, 5, 10, 15, 20]:\n",
        "  for learning_rate in [0.1, 0.01, 0.001]:\n",
        "    for min_child_weight in [1,2,3]:\n",
        "      for gamma in [0.1, 0.2, 0.3]:\n",
        "        InjuryModelXGB1year = xgb.XGBRegressor(tree_method=\"approx\", seed=1, max_depth = depth, learning_rate = learning_rate, min_child_weight = min_child_weight, gamma = gamma, enable_categorical = True)\n",
        "        InjuryModelXGB1year.fit(x1year_train, y1year_train, verbose = True, early_stopping_rounds = 10, eval_set = [(x1year_test, y1year_test)])\n",
        "        y1year_pred = InjuryModelXGB1year.predict(x1year_test)\n",
        "        print(r2_score(y1year_test, y1year_pred))\n",
        "        InjuryModelXGB1year.save_model('xgb_injury_1year_depth' + str(depth) + '_learningrate' + str(learning_rate) + '_childweight' + str(min_child_weight) + '_gamma' + str(gamma) + '_r2score' + str(r2_score(y1year_test, y1year_pred)) + '.json')\n",
        "        files.download('xgb_injury_1year_depth' + str(depth) + '_learningrate' + str(learning_rate) + '_childweight' + str(min_child_weight) + '_gamma' + str(gamma) + '_r2score' + str(r2_score(y1year_test, y1year_pred)) + '.json')"
      ],
      "metadata": {
        "id": "YyJioAPbaTTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1year_pred = InjuryModelXGB1year.predict(x1year_test)\n",
        "print(r2_score(y1year_test, y1year_pred))\n",
        "print(mean_absolute_error(y1year_test, y1year_pred))\n",
        "print(mean_squared_error(y1year_test, y1year_pred))"
      ],
      "metadata": {
        "id": "AS-t2XfUK7ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check sample Ousmane Dembélé, row 5999, why over 365\n",
        "InjuryModelOneYeardf.sample(10)"
      ],
      "metadata": {
        "id": "kgePG2Jtq2T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X6years_train, X6years_test, y6years_train, y6years_test = train_test_split(x6years, y6years, random_state=1, train_size = 0.8)\n",
        "InjuryModelXGB6years = xgb.XGBRegressor(tree_method=\"approx\", seed=1, enable_categorical = True)\n",
        "InjuryModelXGB6years.fit(X6years_train, y6years_train, verbose = True, early_stopping_rounds = 10, eval_set = [(X6years_test, y6years_test)])"
      ],
      "metadata": {
        "id": "mfbGKNPAymUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y6years_pred = InjuryModelXGB6years.predict(X6years_test)\n",
        "print(r2_score(y6years_test, y6years_pred))\n",
        "print(mean_absolute_error(y6years_test, y6years_pred))\n",
        "print(mean_squared_error(y6years_test, y6years_pred))"
      ],
      "metadata": {
        "id": "z26a_ff3MttT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shap test\n",
        "graphviz6years = xgb.to_graphviz(InjuryModelXGB6years)\n",
        "explainer6years = shap.Explainer(graphviz6years)\n",
        "shap_values6years = explainer6years.shap_values(X6years_test)\n",
        "explainer6years.plot_importance(shap_values6years, X6years_test)\n",
        "shap.summary_plot(shap_values6years, X6years_test)"
      ],
      "metadata": {
        "id": "JXlsSzHFQumy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## injury prediction for 1 year sliding window\n",
        "## need to check date joined club, if change club, change values to -1, should be fixed since injury data on all history of player recorded\n",
        "#drop player value column\n",
        "\n",
        "#concatenate repeated players into same row\n",
        "#add features into methods\n",
        "#sliding window, rolling\n",
        "#create numpy array to store r squared/mean squared of accuracy of each model with adjusted hyperparameters\n",
        "#start with set seed\n",
        "#5-10 seeds, find average of models\n",
        "#cross validation"
      ],
      "metadata": {
        "id": "tfPkrT7pYjhw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}